# Quick Task Voice Agent Frontend

A Next.jsÂ +Â TypeScript web client for a voiceâ€‘driven productivity assistant.  
This app records your voice, transcribes it with OpenAI Whisper, routes text to the Quick Task agent, and plays back the agentâ€™s response using ElevenLabs TTS.

---

## ğŸš€ Features

- **Voice Command Recording**  
  Capture spoken input via the browserâ€™s microphone.  
- **Speechâ€‘toâ€‘Text**  
  Transcribe audio using OpenAI Whisper (via `/api/transcribe`).  
- **Agent Chat**  
  Send user text to the Supervisor Agent backend (`/api/agent-chat`) and receive a text response.  
- **Textâ€‘toâ€‘Speech**  
  Convert the agentâ€™s reply into audio with ElevenLabs (`/api/text-to-speech`) and play it back.  
- **Simple UI**  
  A minimal interface for recording, viewing transcript, and listening to responses.

---

## ğŸ“¦ Tech Stack

- **Framework:** Next.js (App Router)  
- **Language:** TypeScript  
- **Styling:** global CSS (can be swapped for Tailwind or other)  
- **TTS:** ElevenLabs API  
- **STT:** OpenAI Whisper API  
- **API Routes:**  
  - `/api/transcribe`  
  - `/api/agent-chat`  
  - `/api/text-to-speech`

---

## ğŸ› ï¸ Prerequisites

- **Node.js** v18+  
- **pnpm**Â (orÂ npm/yarn)  
- **Environment variables** (see below)  

---

## ğŸ”§ Setup & Installation

1. **Clone the repo**  
   ```bash
   https://github.com/shreyasskasetty/quick-task.git
   cd quick-task/voice-agent-frontend
   ```

2. **Install dependencies**  
   ```bash
   pnpm install
   ```

3. **Configure environment variables**  
   Create a `.env.local` in the project root:
   ```ini
   NEXT_PUBLIC_OPENAI_API_KEY=your_openai_api_key
   NEXT_PUBLIC_ELEVENLABS_API_KEY=your_elevenlabs_api_key
   ```
   - `NEXT_PUBLIC_OPENAI_API_KEY` for Whisper transcription  
   - `NEXT_PUBLIC_ELEVENLABS_API_KEY` for ElevenLabs textâ€‘toâ€‘speech  

4. **Run the development server**  
   ```bash
   pnpm dev
   ```
   Open [http://localhost:3000](http://localhost:3000) in your browser.

---

## ğŸš€ Usage

1. Click the **Record** button and speak your command.  
2. The app will display the transcribed text.  
3. Your text is sent to the voiceâ€‘agent backend.  
4. The response is fetched as text, then converted to audio and played automatically.  
5. Repeat as needed to manage calendar events, emails, tasks, or recall memory.

---

## ğŸ“‚ Project Structure

```
voice-agent-frontend/
â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ file.svg
â”‚   â”œâ”€â”€ globe.svg
â”‚   â””â”€â”€ â€¦ (static assets)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ api/
â”‚       â”‚   â”œâ”€â”€ transcribe/ 
â”‚       â”‚   â”‚   â””â”€â”€ route.ts     # Handles Whisper STT
â”‚       â”‚   â”œâ”€â”€ agent-chat/      
â”‚       â”‚   â”‚   â””â”€â”€ route.ts     # Proxies to Supervisor Agent
â”‚       â”‚   â””â”€â”€ text-to-speech/  
â”‚       â”‚       â””â”€â”€ route.ts     # Handles ElevenLabs TTS
â”‚       â”œâ”€â”€ globals.css
â”‚       â”œâ”€â”€ layout.tsx
â”‚       â”œâ”€â”€ page-v1.tsx         # (Optional legacy UI)
â”‚       â””â”€â”€ page.tsx            # Main chat interface
â”œâ”€â”€ .env.example
â”œâ”€â”€ next.config.ts
â”œâ”€â”€ package.json
â”œâ”€â”€ pnpm-lock.yaml
â”œâ”€â”€ postcss.config.mjs
â”œâ”€â”€ eslint.config.mjs
â””â”€â”€ tsconfig.json
```

---

## ğŸ¤ Contributing

1. Fork and clone the repo  
2. Create a branch (`git checkout -b feature/xyz`)  
3. Implement your changes, commit, and push  
4. Open a PR against `main`  

Please follow the existing code style and run any linting/tests before submitting.

---

## ğŸ“„ License

MIT Â© Shreyas Shivakumar Kasetty, Texas A&M University